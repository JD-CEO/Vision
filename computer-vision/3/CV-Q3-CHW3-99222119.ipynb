{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8657618,"sourceType":"datasetVersion","datasetId":5186713}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport torchvision \nfrom torchvision import transforms\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt \nimport cv2\nfrom tqdm.notebook import tqdm\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:23:42.225010Z","iopub.execute_input":"2024-06-13T21:23:42.225469Z","iopub.status.idle":"2024-06-13T21:23:42.231831Z","shell.execute_reply.started":"2024-06-13T21:23:42.225436Z","shell.execute_reply":"2024-06-13T21:23:42.230777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_specific_frame(video_path, frame_num):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        return\n    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n    ret, frame = cap.read()\n    if ret:\n        return frame\n    else:\n        return None\n    \ndef read_specific_line(file_path, line_num):\n    with open(file_path, 'r') as f:\n        lines = f.readlines()\n        if line_num <= len(lines):\n            return float(lines[line_num].strip())\n        else:\n            return None\n        \ndef get_num_frames(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        return -1\n    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    cap.release()\n    return num_frames\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:23:43.030711Z","iopub.execute_input":"2024-06-13T21:23:43.031090Z","iopub.status.idle":"2024-06-13T21:23:43.041021Z","shell.execute_reply.started":"2024-06-13T21:23:43.031060Z","shell.execute_reply":"2024-06-13T21:23:43.039840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pth = \"/kaggle/input/car-speeds/train.mp4\"\ntrain_trg_pth = \"/kaggle/input/car-speeds/train.txt\"\ntest_pth = \"/kaggle/input/car-speeds/test.mp4\"\ntest_trg_pth = \"/kaggle/input/car-speeds/test.txt\"","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:23:45.010193Z","iopub.execute_input":"2024-06-13T21:23:45.010569Z","iopub.status.idle":"2024-06-13T21:23:45.015597Z","shell.execute_reply.started":"2024-06-13T21:23:45.010540Z","shell.execute_reply":"2024-06-13T21:23:45.014421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Speed_Ds(Dataset):\n    def  __init__(self, video_pth, target_pth, transform):\n        super().__init__()\n        self.video_pth, self.target_pth = video_pth, target_pth\n        self.transform = transform\n        \n    def __len__(self):\n        return get_num_frames(self.target_pth) - 1\n    \n    def __getitem__(self,idx):\n        frame1 = torch.tensor(load_specific_frame(self.video_pth, idx)).permute((2,0,1))\n        frame2 = torch.tensor(load_specific_frame(self.video_pth, idx + 1)).permute((2,0,1))\n        target = torch.tensor([read_specific_line(self.target_pth, idx + 1)])\n        return self.transform(frame1), self.transform(frame2), target","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.641309Z","iopub.execute_input":"2024-06-13T20:34:27.641681Z","iopub.status.idle":"2024-06-13T20:34:27.651554Z","shell.execute_reply.started":"2024-06-13T20:34:27.641653Z","shell.execute_reply":"2024-06-13T20:34:27.650608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n#     transforms.Lambda(lambda x: 2*(x/255)-1),\n])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.652849Z","iopub.execute_input":"2024-06-13T20:34:27.653142Z","iopub.status.idle":"2024-06-13T20:34:27.661619Z","shell.execute_reply.started":"2024-06-13T20:34:27.653116Z","shell.execute_reply":"2024-06-13T20:34:27.660556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = Speed_Ds(train_pth, train_trg_pth, transform)\ntest_ds = Speed_Ds(test_pth, test_trg_pth, transform)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.663375Z","iopub.execute_input":"2024-06-13T20:34:27.664426Z","iopub.status.idle":"2024-06-13T20:34:27.672748Z","shell.execute_reply.started":"2024-06-13T20:34:27.664388Z","shell.execute_reply":"2024-06-13T20:34:27.671917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_h, img_w = train_ds[0][0].shape[-2:]\nimg_h,img_w","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.673828Z","iopub.execute_input":"2024-06-13T20:34:27.674128Z","iopub.status.idle":"2024-06-13T20:34:27.871280Z","shell.execute_reply.started":"2024-06-13T20:34:27.674098Z","shell.execute_reply":"2024-06-13T20:34:27.870356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr1, fr2, trg = test_ds[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.872387Z","iopub.execute_input":"2024-06-13T20:34:27.872706Z","iopub.status.idle":"2024-06-13T20:34:27.948272Z","shell.execute_reply.started":"2024-06-13T20:34:27.872669Z","shell.execute_reply":"2024-06-13T20:34:27.947197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def optical_flow_batch(prev_frames, curr_frames):\n    device = prev_frames.device\n    prev_frames = prev_frames.cpu().numpy().transpose(0, 2, 3, 1)\n    curr_frames = curr_frames.cpu().numpy().transpose(0, 2, 3, 1)\n    \n    prev_gray = np.stack([cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in prev_frames])\n    curr_gray = np.stack([cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in curr_frames])\n    \n    flow = np.zeros((prev_frames.shape[0], prev_frames.shape[1], prev_frames.shape[2], 2), dtype=np.float32)\n    for i in range(prev_frames.shape[0]):\n        flow[i] = cv2.calcOpticalFlowFarneback(prev_gray[i], curr_gray[i], None, 0.5, 3, 15, 3, 5, 1.2, 0)\n    flow_tensor = torch.from_numpy(flow).permute(0, 3, 1, 2).float().to(device)\n    return flow_tensor","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.949611Z","iopub.execute_input":"2024-06-13T20:34:27.950449Z","iopub.status.idle":"2024-06-13T20:34:27.958662Z","shell.execute_reply.started":"2024-06-13T20:34:27.950420Z","shell.execute_reply":"2024-06-13T20:34:27.957622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    This one uses optical flow itself as its features\n'''\nclass speed_flow(nn.Module):\n    def __init__(self,img_h, img_w, kernel_size):\n        super().__init__()\n        self.cnv1 = nn.Conv2d(2, 32, kernel_size, padding=int((kernel_size - 1)//2))\n        self.cnv2 = nn.Conv2d(32, 64, kernel_size, padding=int((kernel_size - 1)//2))\n        self.cnv3 = nn.Conv2d(64, 16, 1)\n        self.fc = nn.Linear(img_h*img_w*16, 1)\n        self.tanh = nn.Tanh()\n        self.relu = nn.ReLU()\n    \n    def forward(self,fr1, fr2):\n        B = fr1.shape[0]\n        h = optical_flow_batch(fr1, fr2)\n        h = self.tanh(self.cnv1(h))\n        h = self.tanh(self.cnv2(h))\n        h = self.relu(self.cnv3(h))\n        return self.fc(h.reshape((B,-1)))\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.961612Z","iopub.execute_input":"2024-06-13T20:34:27.961927Z","iopub.status.idle":"2024-06-13T20:34:27.972053Z","shell.execute_reply.started":"2024-06-13T20:34:27.961901Z","shell.execute_reply":"2024-06-13T20:34:27.971225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Sobel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.kernel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n        self.kernel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n        self.kernel_x = self.kernel_x.unsqueeze(0).to(torch.float32)\n        self.kernel_y = self.kernel_y.unsqueeze(0).to(torch.float32)\n    \n    def forward(self, x):\n        grad_x = F.conv2d(x, self.kernel_x.to(x.device).repeat(x.shape[-3],1,1).unsqueeze(1), padding=1, groups=x.shape[-3])\n        grad_y = F.conv2d(x, self.kernel_y.to(x.device).repeat(x.shape[-3],1,1).unsqueeze(1), padding=1, groups=x.shape[-3])\n        return torch.cat([grad_x, grad_y], dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.973099Z","iopub.execute_input":"2024-06-13T20:34:27.973451Z","iopub.status.idle":"2024-06-13T20:34:27.984950Z","shell.execute_reply.started":"2024-06-13T20:34:27.973425Z","shell.execute_reply":"2024-06-13T20:34:27.984000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    This one uses features that optical flow itself has been created on\n'''\nclass Motion_est(nn.Module):\n    def __init__(self,img_h, img_w, kernel_size):\n        super().__init__()\n        self.sobel = Sobel()\n        self.cnv1 = nn.Conv2d(15, 32, kernel_size, padding=int((kernel_size - 1)//2))\n        self.cnv2 = nn.Conv2d(32, 64, kernel_size, padding=int((kernel_size - 1)//2))\n        self.cnv3 = nn.Conv2d(64, 16, 1)\n        self.fc = nn.Linear(img_h*img_w*16, 1)\n        self.tanh = nn.Tanh()\n        self.relu = nn.GELU()\n    \n    def forward(self,fr1, fr2):\n        B = fr1.shape[0]\n        dt = fr2 - fr1\n        dfr1 = self.sobel(fr1)\n        dfr2 = self.sobel(fr2)\n        h = torch.cat([dt, dfr1, dfr2], dim=1)\n        h = self.tanh(self.cnv1(h))\n        h = self.tanh(self.cnv2(h))\n        h = self.relu(self.cnv3(h))\n        return self.fc(h.view((B,-1)))\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:27.986099Z","iopub.execute_input":"2024-06-13T20:34:27.986451Z","iopub.status.idle":"2024-06-13T20:34:28.000334Z","shell.execute_reply.started":"2024-06-13T20:34:27.986427Z","shell.execute_reply":"2024-06-13T20:34:27.999210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_size = 7\nlr = 0.1e-6\nbatch_size = 16\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:28.001659Z","iopub.execute_input":"2024-06-13T20:34:28.002013Z","iopub.status.idle":"2024-06-13T20:34:28.010171Z","shell.execute_reply.started":"2024-06-13T20:34:28.001980Z","shell.execute_reply":"2024-06-13T20:34:28.009194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size, shuffle=True)\ntest_dl = DataLoader(test_ds, batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:28.209136Z","iopub.execute_input":"2024-06-13T20:34:28.210040Z","iopub.status.idle":"2024-06-13T20:34:28.216269Z","shell.execute_reply.started":"2024-06-13T20:34:28.210005Z","shell.execute_reply":"2024-06-13T20:34:28.215271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:28.621419Z","iopub.execute_input":"2024-06-13T20:34:28.621786Z","iopub.status.idle":"2024-06-13T20:34:28.652929Z","shell.execute_reply.started":"2024-06-13T20:34:28.621756Z","shell.execute_reply":"2024-06-13T20:34:28.651449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Motion_est(img_h, img_w, kernel_size).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:29.106011Z","iopub.execute_input":"2024-06-13T20:34:29.106712Z","iopub.status.idle":"2024-06-13T20:34:29.339799Z","shell.execute_reply.started":"2024-06-13T20:34:29.106679Z","shell.execute_reply":"2024-06-13T20:34:29.338853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=lr)\nloss_fun = torch.nn.L1Loss()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:30.033660Z","iopub.execute_input":"2024-06-13T20:34:30.033999Z","iopub.status.idle":"2024-06-13T20:34:30.039496Z","shell.execute_reply.started":"2024-06-13T20:34:30.033974Z","shell.execute_reply":"2024-06-13T20:34:30.038375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def learning(model, train, optimizer, loss_fun, device, epochs):\n    t_losses = []\n    \n    for ep in range(epochs):\n        model.train()\n        pbar = tqdm(enumerate(train))\n        for i, (fr1, fr2, trg) in pbar: # Y=<B, S, C>\n            fr1 = fr1.to(device).to(torch.float32)\n            fr2 = fr2.to(device).to(torch.float32)\n            trg = trg.to(device).to(torch.float32)\n            logits = model(fr1, fr2)\n\n            loss = loss_fun(logits, trg) \n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            t_losses.append(loss.to(\"cpu\").item())\n            pbar.set_description(f\"Epoch : {ep + 1} Training loss is => {loss} \")\n            # del x, y\n            torch.cuda.empty_cache()\n    return model, t_losses\n\n@torch.no_grad()\ndef evluate(model, test, loss_fun, device):\n    t_loss = 0\n    model.eval()\n    pbar = tqdm(enumerate(test))\n    for i, (fr1, fr2, trg) in pbar: # Y=<B, S, C>\n        fr1 = fr1.to(device).to(torch.float32)\n        fr2 = fr2.to(device).to(torch.float32)\n        trg = trg.to(device).to(torch.float32)\n        logits = model(fr1, fr2)\n        loss = loss_fun(logits, trg) \n        t_loss += loss.to(\"cpu\").item()\n            # del x, y\n        torch.cuda.empty_cache()\n    return t_loss/len(test)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:30.936004Z","iopub.execute_input":"2024-06-13T20:34:30.936933Z","iopub.status.idle":"2024-06-13T20:34:30.948505Z","shell.execute_reply.started":"2024-06-13T20:34:30.936897Z","shell.execute_reply":"2024-06-13T20:34:30.947420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, t_losses = learning(model, train_dl, optimizer, loss_fun, device, epochs)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T20:34:31.370499Z","iopub.execute_input":"2024-06-13T20:34:31.370895Z","iopub.status.idle":"2024-06-13T21:17:29.544777Z","shell.execute_reply.started":"2024-06-13T20:34:31.370869Z","shell.execute_reply":"2024-06-13T21:17:29.543637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(t_losses)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:17:29.546812Z","iopub.execute_input":"2024-06-13T21:17:29.547183Z","iopub.status.idle":"2024-06-13T21:17:29.806799Z","shell.execute_reply.started":"2024-06-13T21:17:29.547134Z","shell.execute_reply":"2024-06-13T21:17:29.805818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see it hasnt overfeeted yet thus with more training time we can get much better result than 2 on test data","metadata":{}},{"cell_type":"code","source":"evluate(model, test_dl, loss_fun, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:17:29.808030Z","iopub.execute_input":"2024-06-13T21:17:29.808336Z","iopub.status.idle":"2024-06-13T21:19:30.283001Z","shell.execute_reply.started":"2024-06-13T21:17:29.808310Z","shell.execute_reply":"2024-06-13T21:19:30.281936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef predict(model, fr1, fr2, device):\n    model.eval()\n    fr_ = fr1.to(device).to(torch.float32).unsqueeze(0)\n    fr__ = fr2.to(device).to(torch.float32).unsqueeze(0)\n    return model(fr_,fr__).to(\"cpu\").item()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:19:30.285183Z","iopub.execute_input":"2024-06-13T21:19:30.285527Z","iopub.status.idle":"2024-06-13T21:19:30.291716Z","shell.execute_reply.started":"2024-06-13T21:19:30.285498Z","shell.execute_reply":"2024-06-13T21:19:30.290572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fr,fr_,trg = test_ds[100]\npredict(model, fr, fr_, device), trg","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:23:10.587845Z","iopub.execute_input":"2024-06-13T21:23:10.588222Z","iopub.status.idle":"2024-06-13T21:23:10.843348Z","shell.execute_reply.started":"2024-06-13T21:23:10.588193Z","shell.execute_reply":"2024-06-13T21:23:10.842370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(fr_.permute((1,2,0)).to(\"cpu\").numpy())","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:23:11.389037Z","iopub.execute_input":"2024-06-13T21:23:11.389961Z","iopub.status.idle":"2024-06-13T21:23:11.761921Z","shell.execute_reply.started":"2024-06-13T21:23:11.389925Z","shell.execute_reply":"2024-06-13T21:23:11.760919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_numbers_to_image(img, num1, num2):\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    font_scale = 1\n    blue = (255, 0, 0)\n    green = (0, 255, 0)\n    text = str(num1)\n    (text_width, text_height) = cv2.getTextSize(text, font, font_scale, 2)[0]\n    x = 10\n    y = 20\n    cv2.putText(img, text, (x, y), font, font_scale, blue, 2)\n    text = str(num2)\n    (text_width, text_height) = cv2.getTextSize(text, font, font_scale, 2)[0]\n    x = 10\n    y += text_height + 10\n    cv2.putText(img, text, (x, y), font, font_scale, green, 2)\n    return img\n\ndef create_video_from_images(dataset, fps, output_file):\n    img,_,_ = dataset[0]\n    height, width, layers = img.permute((1,2,0)).to(\"cpu\").numpy().shape\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    video = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n    for i in tqdm(range(len(dataset))):\n        fr,fr_,trg = dataset[i]\n        img = add_numbers_to_image(fr_.permute((1,2,0)).to(\"cpu\").numpy(), round(predict(model, fr, fr_, device),2), round(trg.item(), 2))        \n        video.write(img)\n    video.release()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:19:30.293013Z","iopub.execute_input":"2024-06-13T21:19:30.293639Z","iopub.status.idle":"2024-06-13T21:19:30.306596Z","shell.execute_reply.started":"2024-06-13T21:19:30.293577Z","shell.execute_reply":"2024-06-13T21:19:30.305674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_video_from_images(test_ds, 60, \"/kaggle/working/Speed_test.mp4\")","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:19:30.307714Z","iopub.execute_input":"2024-06-13T21:19:30.308076Z","iopub.status.idle":"2024-06-13T21:21:35.772264Z","shell.execute_reply.started":"2024-06-13T21:19:30.308031Z","shell.execute_reply":"2024-06-13T21:21:35.771222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"YOOOO\")","metadata":{"execution":{"iopub.status.busy":"2024-06-13T21:21:53.656119Z","iopub.execute_input":"2024-06-13T21:21:53.657006Z","iopub.status.idle":"2024-06-13T21:21:53.661974Z","shell.execute_reply.started":"2024-06-13T21:21:53.656971Z","shell.execute_reply":"2024-06-13T21:21:53.661037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}